{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed7c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65570d",
   "metadata": {},
   "source": [
    "## 연산을 수행할 device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0bf2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a219f",
   "metadata": {},
   "source": [
    "# 먼저, 기본적인 CNN layer의 연산 원리를 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871a57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Conv2d(in_channels=1, \n",
    "                out_channels=3, \n",
    "                kernel_size=2, \n",
    "                stride=1, bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e413ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.2565,  0.1148],\n",
      "          [-0.1213,  0.1491]]],\n",
      "\n",
      "\n",
      "        [[[-0.4319, -0.0354],\n",
      "          [-0.4376, -0.4088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3053,  0.4963],\n",
      "          [ 0.1610,  0.3246]]]], requires_grad=True)\n",
      "torch.Size([3, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(cnn.weight)\n",
    "print(cnn.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea9ec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2.],\n",
      "          [2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[3., 3.],\n",
      "          [3., 3.]]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "new_weight = torch.ones((3,1,2,2), dtype=float)\n",
    "\n",
    "new_weight[0] *= 1\n",
    "new_weight[1] *= 2\n",
    "new_weight[2] *= 3\n",
    "\n",
    "print(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a18151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2.],\n",
      "          [2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[3., 3.],\n",
      "          [3., 3.]]]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "cnn.weight = nn.Parameter(new_weight)\n",
    "print(cnn.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d10c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((2, 1, 5, 5), dtype=float) # data수는 2, data channel은 1, (height, width) = (5,5)인 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f612543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.,  4.,  4.,  4.],\n",
      "          [ 4.,  4.,  4.,  4.],\n",
      "          [ 4.,  4.,  4.,  4.],\n",
      "          [ 4.,  4.,  4.,  4.]],\n",
      "\n",
      "         [[ 8.,  8.,  8.,  8.],\n",
      "          [ 8.,  8.,  8.,  8.],\n",
      "          [ 8.,  8.,  8.,  8.],\n",
      "          [ 8.,  8.,  8.,  8.]],\n",
      "\n",
      "         [[12., 12., 12., 12.],\n",
      "          [12., 12., 12., 12.],\n",
      "          [12., 12., 12., 12.],\n",
      "          [12., 12., 12., 12.]]],\n",
      "\n",
      "\n",
      "        [[[ 4.,  4.,  4.,  4.],\n",
      "          [ 4.,  4.,  4.,  4.],\n",
      "          [ 4.,  4.,  4.,  4.],\n",
      "          [ 4.,  4.,  4.,  4.]],\n",
      "\n",
      "         [[ 8.,  8.,  8.,  8.],\n",
      "          [ 8.,  8.,  8.,  8.],\n",
      "          [ 8.,  8.,  8.,  8.],\n",
      "          [ 8.,  8.,  8.,  8.]],\n",
      "\n",
      "         [[12., 12., 12., 12.],\n",
      "          [12., 12., 12., 12.],\n",
      "          [12., 12., 12., 12.],\n",
      "          [12., 12., 12., 12.]]]], dtype=torch.float64,\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "result = cnn(x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6a882",
   "metadata": {},
   "source": [
    "## 1. 네트워크 구조 & Input Flow 작성하기\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>Input(28*28) -> 1st convolution(+relu) + MaxPooling -> 2nd convolution(+relu) + Maxpooling -> (Flatten) -> 1st FFNN(+relu) -> 2nd FFNN </span>\n",
    "\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1st conv</b></span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>in_channel=1, out_channel=64: </b>1개 channel을 갖는 image를 받아 64개의 channel을 생성</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>kernel_size=(3,3): </b>채널의 각 위치의 값을 계산하는 kernel의 크기는 height 3, width 3. 이러한 kernel이 1*64개만큼 생성됨</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>stride=(1,1), padding=1: </b>kernel의 이동은 세로로 1, 가로로 1만큼. conv층에 들어오는 데이터에 padding을 양옆에 1만큼 해줌</span>\n",
    "\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1st MaxPooling</b></span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>kernel_size=(2,2): </b>kernel의 크기는 height 2, width 2. 이러한 kernel이 conv layer의 out_channel개만큼 생성됨</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>stride=(2,2): </b>kernel의 이동은 세로로 2, 가로로 2만큼.</span>\n",
    "        \n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>2st conv</b></span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>in_channel=64, out_channel=128: </b>64개 channel을 갖는 1st MaxPooling 층의 output값을 받아 128개의 channel을 생성</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>kernel_size=(3,3): </b>채널의 각 위치의 값을 계산하는 kernel의 크기는 height 3, width 3. 이러한 kernel이 64*128개만큼 생성됨</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>stride=(1,1), padding=1: </b>kernel의 이동은 세로로 1, 가로로 1만큼. conv층에 들어오는 데이터에 padding을 양옆에 1만큼 해줌</span>\n",
    "\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>2nd MaxPooling</b></span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>kernel_size=(2,2): </b>kernel의 크기는 height 2, width 2. 이러한 kernel이 conv layer의 out_channel개만큼 생성됨</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>stride=(2,2): </b>kernel의 이동은 세로로 2, 가로로 2만큼.</span>\n",
    "        \n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>Flatten</b></span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>x.reshape(): </b>FFNN의 입력값으로 넣을 수 있도록, 2nd Pooling Layer의 결과 값인 (batch_size, 128, 7, 7) 크기의 tensor를 (batch_size, 128\\*7\\*7)크기의 tensor로 형태 변환</span>\n",
    "        \n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1st FFNN, 2nd FFNN</b></span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>1st FFNN: </b>7\\*7\\*128차원의 벡터를 100차원의 벡터로 보내는 FFNN (with relu 활성화 함수)</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'><b>2nd FFNN: </b>100차원의 벡터를 10차원(=class 수)의 벡터로 보내는 FFNN (원래는 softmax함수를 함께 써야 하지만, Pytorc)</span>\n",
    "            - <span style = 'font-size:0.9em;line-height:1.5em'>원래는 softmax함수를 함께 써야 하지만, Pytorch의 cross_entropy함수의 특성상, softmax를 생략</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e09394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.fc1   = nn.Linear(7*7*128, 100, bias=True)\n",
    "        self.fc2   = nn.Linear(100, 10, bias=True)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, submodule):\n",
    "        if isinstance(submodule, nn.Conv2d):\n",
    "            nn.init.xavier_normal_(submodule.weight)\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01)\n",
    "        if isinstance(submodule, nn.Linear): # submodule이 nn.Linear에서 생성된 객체(혹은 인스턴스이면)\n",
    "            nn.init.kaiming_normal_(submodule.weight) #해당 submodule의 weight는 He Initialization으로 초기화\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01) # 해당 submodule의 bias는 0.01로 초기화\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # (n_data, n_channel, height, width)으로 연산 결과의 크기 표기\n",
    "        # 1st conv layer\n",
    "        out = self.conv1(x) # shape: (batch,1,28,28) -> (batch,32,28,28)\n",
    "        out = F.relu(out) \n",
    "        out = self.pool1(out) # (batch,32,28,28) -> (batch,32,14,14)\n",
    "        \n",
    "        # 2nd conv layer\n",
    "        out = self.conv2(out) # (batch,32,14,14) -> (batch,64,14,14)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool2(out) # (batch,64,14,14) -> (batch,64,7,7)\n",
    "        \n",
    "        # Flatten\n",
    "        out = out.reshape(-1, 7*7*128)\n",
    "        \n",
    "        # 1st FFNN\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        # 2nd FFNN\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad58ff",
   "metadata": {},
   "source": [
    "## 2. pytorch 모델을 학습하기 위한 데이터 셋 생성하기 \n",
    "### (By datasets, transforms (in torchvision))\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'><b>1.</b> 데이터를 다운받을 디렉토리 선언 (optional)</span>\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'><b>2.</b> 데이터를 변환할 방법 선언(예시: numpy array 형태의 데이터를 torch Tensor로</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>torch 모델에 입력하는 데이터도 반드시 torch tensor여야 합니다.</span>\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'><b>3.</b> 데이터 셋 생성(다운로드 여부, 학습/평가 데이터 여부, 데이터 변환 방법 등)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30724ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261168c4f1b84e2db92e5c9074e79f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac8ac72cee0435b9e6e0c230b72edfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99cfab717b24d6992c49948d414d54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f5570d0107404da0fcca0dac061ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    \n",
    "transform = transforms.Compose([transforms.ToTensor(), # 이미지를 텐서로 변경하고\n",
    "                                transforms.Normalize((0.1307,),(0.3081,))  # 이미지를 0.1307, 0.3081값으로 normalize (나중에 봅시다.)\n",
    "                               ])\n",
    "\n",
    "trn_dset = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)\n",
    "tst_dset = datasets.MNIST(root=data_path, train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ada111",
   "metadata": {},
   "source": [
    "## 3. Mini-batch 데이터를 자동으로 생성해주는 DataLoader 생성하기\n",
    "### (By DataLoader class (in torch.utils.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcbdd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 2**9\n",
    "trn_loader = DataLoader(trn_dset, batch_size = BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "tst_loader = DataLoader(tst_dset, batch_size = BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc701f",
   "metadata": {},
   "source": [
    "## 4. 모델 객체를 생성하고 이 모델을 GPU에서 사용할지 GPU에서 사용할지 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6beec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b29c1b",
   "metadata": {},
   "source": [
    "## 5. Optimizer 설정하기 (Create an optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f65e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "my_opt = optim.Adam(params = model.parameters(), lr = 2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563a7a2",
   "metadata": {},
   "source": [
    "## 6. loss function 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb037f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a814fa",
   "metadata": {},
   "source": [
    "## 7. 매 Epoch에 드는 시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46bf149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614fc03",
   "metadata": {},
   "source": [
    "## 8. 학습을 해봅시다.\n",
    "\n",
    "### 1. Train the model\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>Mini-batch train data에 대해서 다음과 같은 과정을 수행합니다. (모든 train data를 다 입력할 때 까지 = 1 epoch)</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1-(1).</b> mini-batch x,y를 모델에 입력합니다. `x.shape = (n_data,1,28,28)`, `y.shape=(n_data)`. 동시에 모델이 gpu에 있으면 data도 gpu로 올려줍니다.</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'> <b>n_data: </b>mini-batch data수, <b>1: </b>channel수(흑백이라서 단일 채널. 칼라 이미지(RGB)는 기본으로 3으로 설정됨) <b>28: </b>Width, <b>28: </b>height</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1-(2).</b> 이전 단계에서 계산되어 남아있는 optimizer의 gradient 값들을 전부 0으로 비워줍니다. (안그럼 계속 누적되어서 계산됩니다!)</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1-(3).</b> Forward Propagation: Mini-batch 데이터를 모델에 입력하여 최종 output값을 계산하는 forward propagation을 진행합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1-(4).</b> Loss Calculation: 실제 y와 모델이 예측한 y사이의 loss를 구합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1-(5).</b> Gradient Calculation: Loss로부터 모델의 모든 parameter의 gradient를 계산합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1-(6).</b> BackPropgation: 계산된 gradient를 활용하여 각 parameter값을 update합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>1-(7).</b> trn_loss에 minibatch loss를 누적해서 계산하기</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d0f4f",
   "metadata": {},
   "source": [
    "### 2. Evaluate the model (for validation)\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>Mini-batch validation data에 대해서 다음과 같은 과정을 수행합니다. (단, validation에서는 학습을 진행하면 안되기 때문에, `torch.no_grad()`와 `model.eval()`가 반드시 필요)</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>2-(1).</b> mini-batch x,y를 모델에 입력합니다. `x.shape = (n_data,1,28,28)`, `y.shape=(n_data)`. 동시에 모델이 gpu에 있으면 data도 gpu로 올려줍니다.</span>\n",
    "        - <span style = 'font-size:1.0em;line-height:1.5em'> <b>n_data: </b>mini-batch data수, <b>1: </b>channel수(흑백이라서 단일 채널. 칼라 이미지(RGB)는 기본으로 3으로 설정됨) <b>28: </b>Width, <b>28: </b>height</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>2-(2).</b> Forward Propagation: Mini-batch validation 데이터를 모델에 입력하여 최종 output값을 계산하는 forward propagation을 진행합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'><b>2-(3).</b> 매 epoch마다 validation set에서 성능이 어떻게 변하는지 모니터링 하기 위해 모델이 예측한 결과와 loss를 계산합니다. 그리고 그 결과를 계속해서 누적합니다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3c781",
   "metadata": {},
   "source": [
    "### 3. 전체 결과 출력\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>Mini-batch별 예측 결과와 정답을 누적하여 전체 예측 결과와 전체 정답을 만든 뒤, mean test error와 accuracy를 산출</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20f1ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 43s\n",
      "\tTrain Loss: 0.140 | Test Loss: 0.093 | Test Acc: 97.460% \n",
      "Epoch: 02 | Time: 1m 43s\n",
      "\tTrain Loss: 0.087 | Test Loss: 0.071 | Test Acc: 97.830% \n",
      "Epoch: 03 | Time: 1m 43s\n",
      "\tTrain Loss: 0.067 | Test Loss: 0.052 | Test Acc: 98.400% \n",
      "Epoch: 04 | Time: 1m 43s\n",
      "\tTrain Loss: 0.055 | Test Loss: 0.049 | Test Acc: 98.380% \n",
      "Epoch: 05 | Time: 1m 44s\n",
      "\tTrain Loss: 0.048 | Test Loss: 0.039 | Test Acc: 98.720% \n",
      "Epoch: 06 | Time: 1m 44s\n",
      "\tTrain Loss: 0.041 | Test Loss: 0.038 | Test Acc: 98.740% \n",
      "Epoch: 07 | Time: 1m 44s\n",
      "\tTrain Loss: 0.037 | Test Loss: 0.038 | Test Acc: 98.800% \n",
      "Epoch: 08 | Time: 1m 43s\n",
      "\tTrain Loss: 0.034 | Test Loss: 0.034 | Test Acc: 98.790% \n",
      "Epoch: 09 | Time: 1m 43s\n",
      "\tTrain Loss: 0.031 | Test Loss: 0.038 | Test Acc: 98.690% \n",
      "Epoch: 10 | Time: 1m 44s\n",
      "\tTrain Loss: 0.028 | Test Loss: 0.036 | Test Acc: 98.720% \n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터를 n_epoch(10)번 반복하여 넣을 때 까지 학습합니다.\n",
    "n_epochs = 10\n",
    "\n",
    "# 매 epoch마다 반복\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    trn_loss = 0\n",
    "    # 매 mini-batch train data마다 반복\n",
    "    for i, (x, y) in enumerate(trn_loader):\n",
    "        # 1-(1): 모델에 입력하기 위해서 데이터의 형태 변환\n",
    "        x = x.to(device) # x.shape: (batch_size,1, 28,28)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # 1-(2): 기존에 계산된 gradient를 0으로 reset\n",
    "        my_opt.zero_grad()\n",
    "        \n",
    "        # 1-(3): Forward Propagation\n",
    "        y_pred_prob = model(x)\n",
    "        \n",
    "        # 1-(4): Loss Calculation\n",
    "        loss = loss_func(y_pred_prob, y)\n",
    "        \n",
    "        # 1-(5): Gradient Calculation(Backprop)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 1-(6): Update parameter\n",
    "        my_opt.step()\n",
    "        \n",
    "        # 1-(7): trn_loss에 mini_batch loss를 누적해서 계산하기\n",
    "        trn_loss += loss.item()\n",
    "        \n",
    "    trn_loss /= len(trn_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    results_pred = []\n",
    "    results_real = []\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        # 매 mini-batch validation data마다 반복\n",
    "        for i, (x, y) in enumerate(tst_loader):\n",
    "            # 2-(1)\n",
    "            x = x.to(device) # x.shape: (batch_size,1,28,28)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # 2-(2)\n",
    "            y_pred_prob = model(x)\n",
    "            y_pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "            # 2-(3)\n",
    "            loss = loss_func(y_pred_prob, y)\n",
    "            val_loss += loss\n",
    "            \n",
    "            results_pred.extend(y_pred_label.cpu().detach().numpy())\n",
    "            results_real.extend(y.cpu().detach().numpy())\n",
    "            \n",
    "        # 3.\n",
    "        val_loss /= len(tst_loader.dataset)\n",
    "        results_pred = np.array(results_pred)\n",
    "        results_real = np.array(results_real)\n",
    "        accuracy = np.sum(results_pred == results_real) / len(tst_loader.dataset)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {trn_loss:.3f} | Test Loss: {val_loss:.3f} | Test Acc: {100*accuracy:.3f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da2b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
